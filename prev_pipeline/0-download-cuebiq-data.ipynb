{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__countries we have access to data for__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso2_to_iso3 = {\n",
    "                'CO':'COL', # colombia\n",
    "                'CI':'CIV', # cote d'ivoire\n",
    "                'ID':'IDN', # indonesia\n",
    "                'IN':'IND', # india\n",
    "                'MM':'MMR', # myanmar\n",
    "                'MX':'MEX', # mexico\n",
    "                'MY':'MYS', # malaysia\n",
    "                'MZ':'MOZ', # mozambique \n",
    "                'NG':'NGA', # nigeria\n",
    "                'UA':'UKR', # ukraine\n",
    "                'US':'USA', # usa\n",
    "                'GB':'GBR', # great britain\n",
    "                'AU':'AUS', # australia\n",
    "                'DE':'DEU', # germany\n",
    "               }\n",
    "\n",
    "programme_countries = ['CO','CI','ID','IN','MM','MX','MY','MZ','NG','UA']\n",
    "non_programme_countries = ['AU','DE','GB','US']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List most recent data-files for countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRAMME COUNTRIES\n",
      "\t CIV ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t COL ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t IDN ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t IND ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t MMR ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t MEX ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t MYS ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t MOZ ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t NGA ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "\t UKR ['2021040300', '2021040400', '2021040500', '2021040600', '2021040700']\n",
      "NON-PROGRAMME COUNTRIES\n",
      "\t AUS ['2021012900', '2021013000', '2021013100', '2021020100', '2021020200']\n",
      "\t DEU ['2021012900', '2021013000', '2021013100', '2021020100', '2021020200']\n",
      "\t GBR ['2021012900', '2021013000', '2021013100', '2021020100', '2021020200']\n",
      "\t USA ['2020062600', '2020062700', '2020062800', '2020062900', '2020063000']\n"
     ]
    }
   ],
   "source": [
    "print('PROGRAMME COUNTRIES')\n",
    "for iso2 in sorted(programme_countries):\n",
    "    iso3 = iso2_to_iso3[iso2]    \n",
    "    print('\\t',iso3,os.listdir('/home/vsekara/mb-data/cuebiq-raw/%s/' % iso3)[-5:]) # sunmin changed it from \"mb_data\"\n",
    "\n",
    "print('NON-PROGRAMME COUNTRIES')\n",
    "for iso2 in sorted(non_programme_countries):\n",
    "    iso3 = iso2_to_iso3[iso2]\n",
    "    print('\\t',iso3,os.listdir('/home/vsekara/mb-data/cuebiq-raw/%s/' % iso3)[-5:]) # sunmin changed it from \"mb_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE 2020070100/\r\n",
      "                           PRE 2020070200/\r\n",
      "                           PRE 2020070300/\r\n",
      "                           PRE 2020070400/\r\n",
      "                           PRE 2020070500/\r\n",
      "                           PRE 2020070600/\r\n",
      "                           PRE 2020070700/\r\n",
      "                           PRE 2020070800/\r\n",
      "                           PRE 2020070900/\r\n",
      "                           PRE 2020071000/\r\n",
      "                           PRE 2020071100/\r\n",
      "                           PRE 2020071200/\r\n",
      "                           PRE 2020071300/\r\n",
      "                           PRE 2020071400/\r\n",
      "                           PRE 2020071500/\r\n",
      "                           PRE 2020071600/\r\n",
      "                           PRE 2020071700/\r\n",
      "                           PRE 2020071800/\r\n",
      "                           PRE 2020071900/\r\n",
      "                           PRE 2020072000/\r\n",
      "                           PRE 2020072100/\r\n",
      "                           PRE 2020072200/\r\n",
      "                           PRE 2020072300/\r\n",
      "                           PRE 2020072400/\r\n",
      "                           PRE 2020072500/\r\n",
      "                           PRE 2020072600/\r\n",
      "                           PRE 2020072700/\r\n",
      "                           PRE 2020072800/\r\n",
      "                           PRE 2020072900/\r\n",
      "                           PRE 2020073000/\r\n",
      "                           PRE 2020073100/\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://cuebiq-dataset-nv/d4g/covid-19/CI/202007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CO\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "CI\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t removed file part-00000-c99cdf42-6083-4b82-8de1-f75912507b9e-c000.csv.gz because it was below 40kb\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "ID\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "IN\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "MM\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "MX\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "MY\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "MZ\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t removed file part-00000-0b85f000-0713-4475-a964-cfe4cccd6d69-c000.csv.gz because it was below 40kb\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "NG\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n",
      "UA\n",
      "\t Downloading data for \t2020070800\n",
      "\t Downloading data for \t2020070900\n",
      "\t Downloading data for \t2020071000\n",
      "\t Downloading data for \t2020071100\n",
      "\t Downloading data for \t2020071200\n"
     ]
    }
   ],
   "source": [
    "# days to download data for\n",
    "t_start = datetime(2020,2,1)\n",
    "\n",
    "t_end = datetime.now() - timedelta(days = 1)\n",
    "t_end = datetime(t_end.year,t_end.month,t_end.day)\n",
    "\n",
    "# loop over countries\n",
    "for iso2 in programme_countries:\n",
    "    t = t_start\n",
    "    print(iso2)\n",
    "    iso3 = iso2_to_iso3[iso2]\n",
    "    \n",
    "    # loop over days\n",
    "    while t <= t_end:\n",
    "        # handle paths\n",
    "        folder_name = t.strftime('%Y%m%d00')\n",
    "        call_path = 'aws s3 sync s3://cuebiq-dataset-nv/d4g/covid-19/' + iso2 + '/' + folder_name\n",
    "        save_path = '/home/vsekara/mb_data/cuebiq-raw/' + iso2_to_iso3[iso2] + '/' + folder_name\n",
    "        \n",
    "        # check if folder already exists\n",
    "        if os.path.exists(save_path) == False:\n",
    "            print('\\t Downloading data for \\t' + folder_name)\n",
    "            \n",
    "            # download data \n",
    "            subprocess.call(call_path + ' ' + save_path,shell=True)\n",
    "        \n",
    "            # iterate over files and check size\n",
    "            for file in [f for f in os.listdir(save_path) if '.csv.gz' in f]:\n",
    "                # if file below 40 kb\n",
    "                if os.path.getsize(save_path+'/'+file) < 40:\n",
    "                    # delete file\n",
    "                    os.remove(save_path+'/'+file)\n",
    "                    print('\\t removed file %s because it was below 40kb'% file)\n",
    "    \n",
    "        # increment time counter\n",
    "        t += timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use this link to compute stops:\n",
    "https://52.186.123.71:8000/user/vsekara/notebooks/turingdata2code/vsekara/cuebiq/data-processing-pipeline/1-compute-stops.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='red'> download data for individual countries </font>\n",
    "Used when we need to download the full data for a country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # days to down download data from\n",
    "# t_start = datetime(2020,1,16)\n",
    "# t_end = datetime(2020,1,31)\n",
    "\n",
    "# # loop over countries\n",
    "# iso2 = 'US'\n",
    "# #iso2 = 'GB'\n",
    "# #iso2 = 'AU'\n",
    "# #iso2 = 'DE'\n",
    "# iso3 = iso2_to_iso3[iso2]\n",
    "# t = t_start\n",
    "# print(iso3)\n",
    "    \n",
    "# # loop over days\n",
    "# while t <= t_end:\n",
    "    \n",
    "#     folder_name = t.strftime('%Y%m%d00')\n",
    "#     call_path = 'aws s3 sync s3://cuebiq-dataset-nv/d4g/covid-19/' + iso2 + '/' + folder_name\n",
    "#     save_path = '/home/vsekara/mb_data/cuebiq-raw/' + iso2_to_iso3[iso2] + '/' + folder_name\n",
    "    \n",
    "#     # check if folder already exists\n",
    "#     if os.path.exists(save_path) == False:    \n",
    "#         print('Downloading data for ' + folder_name)\n",
    "        \n",
    "#         # download data\n",
    "#         subprocess.call(call_path + ' ' + save_path,shell=True)\n",
    "\n",
    "#         # iterate over files and check size\n",
    "#         for file in [f for f in os.listdir(save_path) if '.csv.gz' in f]:\n",
    "#             # if file below 40 kb\n",
    "#             if os.path.getsize(save_path+'/'+file) < 40:\n",
    "#                 # delete file\n",
    "#                 os.remove(save_path+'/'+file)\n",
    "#                 print('\\t removed file %s because it was below 40kb'% file)\n",
    "\n",
    "#     t += timedelta(days = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
