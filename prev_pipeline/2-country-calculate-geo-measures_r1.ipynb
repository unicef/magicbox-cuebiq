{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__v1.3__\n",
    "<br/>\n",
    "Due to issues found in the POI aggregation pipeline (regarding low data coverage for non-programme countries) this notebook has been updated to reflect that POIs are now all stored in one file.\n",
    "Also to mititage some of the issues with bad user data the stored geomeasures now include a coverage column indicating for how many hours of the day we have data coverage for.\n",
    "\n",
    "__v1.2__\n",
    "<br/>\n",
    "Changing the format of save-files, such that we now are not storing urban (1)/rural (0) indicator, home location (lat,lon) for each day for each user, so we later can easier merge with other data. Also streamlined the calculation piece, such that poverty look-up is also done here\n",
    "\n",
    "__v1.1__\n",
    "<br/>\n",
    "Put everyting into functions to automate code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import shapely\n",
    "import operator\n",
    "import rasterio\n",
    "import math\n",
    "import copy\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arguments + functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interval_data(path_,day_,file_):\n",
    "    # load interval data\n",
    "    interval_data = pd.read_csv(path_ + day_ + \"/\" + file_)\n",
    "\n",
    "    return interval_data\n",
    "\n",
    "def load_stops_data(path_,day_,file_):\n",
    "    # load data for centroids\n",
    "    stops_data = pd.read_csv(path_ + day_ + \"/\" + file_)    \n",
    "    \n",
    "    return  stops_data\n",
    "\n",
    "def haversine_distance(lat1,lon1,lat2,lon2):\n",
    "    radius = 6371 # radius of earth in km\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d\n",
    "\n",
    "def infer_home_label(types_,labels_,admins_,starts_,ends_):\n",
    "    home = Counter()\n",
    "    for i,l in enumerate(labels_):\n",
    "        if l != -1:\n",
    "            home[(l,admins_[i])] += ends_[i] - starts_[i]\n",
    "    \n",
    "    if home != Counter():\n",
    "        return home.most_common(1)[0]\n",
    "    else:\n",
    "        return ((-1,-1),-1)\n",
    "    \n",
    "def calculate_radius_of_gyration(labels_,positions_,home_label):\n",
    "    # create dict of positions\n",
    "    loc_dict = dict(zip(labels_,positions_))\n",
    "\n",
    "    # only calculate radius of unique set of points\n",
    "    labels_ = set(labels_)\n",
    "    # remove the home location\n",
    "    labels_.remove(home_label)\n",
    "    # count number of labels\n",
    "    n = len(labels_)\n",
    "    if n > 0:\n",
    "        # calculate distance between labels and home label\n",
    "        rg_ = []\n",
    "        home_lat, home_lon = loc_dict[home_label]\n",
    "        for l in labels_:\n",
    "            if l != -1:\n",
    "                lat_,lon_ = loc_dict[l]\n",
    "                # add to list\n",
    "                rg_.append(haversine_distance(home_lat,home_lon,lat_,lon_)**2)\n",
    "        # calculate radius using (eq S2) from Gonzales et al. Understanding individual human mobility patterns\n",
    "        return np.sqrt(1/float(n)*sum(rg_))\n",
    "    else:\n",
    "        return -1  # person has not moved\n",
    "    \n",
    "def get_value_from_raster(raster,band,lat,lon,max_row,max_col):\n",
    "    row,col = raster.index(lon,lat)\n",
    "\n",
    "    if  0 <= row < max_row and 0 <= col < max_col:\n",
    "        return band[row, col]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def load_urban_raster():\n",
    "    # open raster image containing urban/rural info\n",
    "    raster = rasterio.open('/home/vsekara/mb_data/magicbox-public/settlements/GHS_SMOD_1km/GHS_SMOD_POP2015_GLOBE_R2019A_54009_1K_V2_0_RPJ.tif')\n",
    "\n",
    "    # read settlement raster\n",
    "    band = raster.read(1)\n",
    "    # modify array\n",
    "    band[band <= 10] = -1 # nothing\n",
    "    band[(11 <= band) & (band <= 13)] = 0 # rural\n",
    "    band[21 <= band] = 1 # urban\n",
    "    max_row, max_col = band.shape\n",
    "    \n",
    "    return raster, band, max_row, max_col\n",
    "    \n",
    "def load_poverty_raster(country):\n",
    "    # load poverty data\n",
    "    pov_data = {\n",
    "        'NGA':'/home/vsekara/mb_data/magicbox-public/poverty/NGA/worldpop/nga10povcons200.tif',\n",
    "        'IDN':'/home/vsekara/mb_data/magicbox-public/poverty/IDN/idn_poverty_rate.tif',\n",
    "        'MOZ':'/home/vsekara/mb_data/magicbox-public/poverty/MOZ/AtlasAI/mozambique_rpj.tif',\n",
    "        'CIV':'/home/vsekara/mb_data/magicbox-public/poverty/CIV/AtlasAI/cotedivoire_rpj.tif',\n",
    "        'COL':'/home/vsekara/mb_data/magicbox-public/poverty/COL/DANE/poverty_colombia_mun.tif',\n",
    "    }\n",
    "\n",
    "    raster_path = pov_data[country]\n",
    "    \n",
    "    # open raster image\n",
    "    raster = rasterio.open(raster_path)\n",
    "    # read poverty raster\n",
    "    band = raster.read(1)\n",
    "    # threshold array\n",
    "    band[band < 1e-3] = 0\n",
    "    max_row, max_col = band.shape\n",
    "    \n",
    "    return raster, band, max_row, max_col\n",
    "\n",
    "#countries_with_povdata = {'NGA','IDN','COL','CIV','MOZ'}\n",
    "countries_with_povdata = {'NGA','COL','CIV','MOZ'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate 1) dist travlled 2) time spent at home 3) r_gyration, 4) no. pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_geostats(country,t_day,t_end,admin='admin1'):\n",
    "\n",
    "    # define paths\n",
    "    if admin == \"admin1\":\n",
    "        stop_path = \"/home/vsekara/mb_data/cuebiq/nCoV/POI/%s/stops_gz/\" % country\n",
    "        admin_key = 'GID_1'\n",
    "    elif admin == 'admin2':\n",
    "        stop_path = \"/home/vsekara/mb_data/cuebiq/nCoV/POI/%s/stops_gz_level_2/\" % country\n",
    "        admin_key = 'GID_2'\n",
    "    interval_path = \"/home/vsekara/mb_data/cuebiq/nCoV/POI/%s/intervals_gz/\" % country\n",
    "    save_path = \"/home/vsekara/mb_data/cuebiq/nCoV/geostats/%s/\" % country\n",
    "\n",
    "    # check if save path exists\n",
    "    if os.path.exists(save_path) == False:\n",
    "        # otherwise create directory\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    # name of files to open\n",
    "    file = 'all_parts.csv.gz'\n",
    "\n",
    "    # load urban raster\n",
    "    urban_raster, urban_band, urban_max_row, urban_max_col = load_urban_raster()\n",
    "    if country in countries_with_povdata:\n",
    "        poverty_raster, poverty_band, pov_max_row, pov_max_col = load_poverty_raster(country)\n",
    "        POVERTY = True\n",
    "        columns = ['useruuid',admin,'distance_travelled','number_of_pois','radius_of_gyration',\n",
    "                    'time_at_home','latitude','longitude','time_coverage','urban','poverty']\n",
    "    else:\n",
    "        POVERTY = False\n",
    "        columns = ['useruuid',admin,'distance_travelled','number_of_pois',\n",
    "                    'radius_of_gyration','time_at_home','latitude','longitude','time_coverage','urban']\n",
    "\n",
    "    # iterate of days\n",
    "    while t_day <= t_end:\n",
    "        day = t_day.strftime('%Y%m%d00')\n",
    "\n",
    "        # if file does not exist - do analysis\n",
    "        if os.path.exists(save_path + '%s.csv' % day) == False:\n",
    "\n",
    "            # print the file it is starting to work on\n",
    "            print(country,day)\n",
    "\n",
    "            # load interval data\n",
    "            interval_data = load_interval_data(interval_path,day,file)\n",
    "            # load stops data\n",
    "            stops_data = load_stops_data(stop_path,day,file)\n",
    "            # create stop_to_admin1 map\n",
    "            stops_to_admin1 = dict(zip(stops_data['label'],stops_data['GID_2']))\n",
    "            # create stops to gps pos\n",
    "            stops_to_pos = dict(zip(stops_data['label'],zip(stops_data['latitude'],stops_data['longitude'])))\n",
    "\n",
    "            # DISTANCE CALCULATION\n",
    "            dist = interval_data.groupby('useruuid').agg({'distance':'sum'}).reset_index()\n",
    "\n",
    "            # HOME LOCATION COUNT\n",
    "            visits = (interval_data.groupby('useruuid')\n",
    "                          .agg({'start': list, 'end': list,\n",
    "                                'classification_type': list,\n",
    "                                'label': list,\n",
    "                                'distance':'sum'\n",
    "                              }).reset_index()[['useruuid','classification_type','label','start','end','distance']].values)\n",
    "\n",
    "            # after reading file calculate statistics\n",
    "            save_data = []\n",
    "            for u,types,labels,starts,ends,dist in visits:\n",
    "\n",
    "                # unpack list of tuples\n",
    "                admins = [stops_to_admin1.get(l,-1) for l in labels]\n",
    "                positions = [stops_to_pos.get(l,-1) for l in labels]\n",
    "\n",
    "                # calculate data coverage\n",
    "                time_coverage = sum(np.array(ends) - np.array(starts))\n",
    "\n",
    "                # find home location\n",
    "                (home_label,admin_label),time_at_home = infer_home_label(types,labels,admins,starts,ends)\n",
    "\n",
    "                # calculate radius of gyration\n",
    "                rg = round(calculate_radius_of_gyration(labels,positions,home_label),3)\n",
    "\n",
    "                # calculate number of points of interest \n",
    "                pois = len([l for l in set(labels) if l!=-1])\n",
    "\n",
    "                # get urban label of home area\n",
    "                if home_label!=-1:\n",
    "                    # find home gps locations\n",
    "                    lat,lon = map(lambda x: round(x,5), positions[labels.index(home_label)])\n",
    "                    urban = get_value_from_raster(urban_raster,urban_band,lat,lon,urban_max_row,urban_max_col)\n",
    "                else:\n",
    "                    urban = -1\n",
    "                    lat,lon = float(\"NaN\"),float(\"NaN\")\n",
    "                save_row = (u,admin_label,round(dist,3),pois,rg,time_at_home,lat,lon,time_coverage,urban)\n",
    "\n",
    "                # if we have poverty data for the country get poverty of home area\n",
    "                if POVERTY:\n",
    "                    if home_label!=-1:\n",
    "                        poverty = get_value_from_raster(poverty_raster,poverty_band,lat,lon,pov_max_row,pov_max_col)\n",
    "                    else:\n",
    "                        poverty = -1\n",
    "                    save_row += (poverty,)\n",
    "\n",
    "                # append data to list\n",
    "                save_data.append(save_row)\n",
    "\n",
    "            # save file\n",
    "            pd.DataFrame(save_data,columns=columns).to_csv(save_path + '%s.csv' % day,index=False)\n",
    "\n",
    "        t_day += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel/__main__.py:98: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIV 2020010100\n",
      "CIV 2020010200\n",
      "CIV 2020010300\n",
      "CIV 2020010400\n",
      "CIV 2020010500\n",
      "CIV 2020010600\n",
      "CIV 2020010700\n",
      "CIV 2020010800\n",
      "CIV 2020010900\n",
      "CIV 2020011000\n",
      "CIV 2020011100\n",
      "CIV 2020011200\n",
      "CIV 2020011300\n",
      "CIV 2020011400\n",
      "CIV 2020011500\n",
      "CIV 2020011600\n",
      "CIV 2020011700\n",
      "CIV 2020011800\n",
      "CIV 2020011900\n",
      "CIV 2020012000\n",
      "CIV 2020012100\n",
      "CIV 2020012200\n",
      "CIV 2020012300\n",
      "CIV 2020012400\n",
      "CIV 2020012500\n",
      "CIV 2020012600\n",
      "CIV 2020012700\n",
      "CIV 2020012800\n",
      "CIV 2020012900\n",
      "CIV 2020013000\n",
      "CIV 2020013100\n",
      "COL 2020010100\n",
      "COL 2020010200\n",
      "COL 2020010300\n",
      "COL 2020010400\n",
      "COL 2020010500\n",
      "COL 2020010600\n",
      "COL 2020010700\n",
      "COL 2020010800\n",
      "COL 2020010900\n",
      "COL 2020011000\n",
      "COL 2020011100\n",
      "COL 2020011200\n",
      "COL 2020011300\n",
      "COL 2020011400\n",
      "COL 2020011500\n",
      "COL 2020011600\n",
      "COL 2020011700\n",
      "COL 2020011800\n",
      "COL 2020011900\n",
      "COL 2020012000\n",
      "COL 2020012100\n",
      "COL 2020012200\n",
      "COL 2020012300\n",
      "COL 2020012400\n",
      "COL 2020012500\n",
      "COL 2020012600\n",
      "COL 2020012700\n",
      "COL 2020012800\n",
      "COL 2020012900\n",
      "COL 2020013000\n",
      "COL 2020013100\n",
      "IDN 2020010100\n",
      "IDN 2020010200\n",
      "IDN 2020010300\n",
      "IDN 2020010400\n",
      "IDN 2020010500\n",
      "IDN 2020010600\n",
      "IDN 2020010700\n",
      "IDN 2020010800\n",
      "IDN 2020010900\n",
      "IDN 2020011000\n",
      "IDN 2020011100\n",
      "IDN 2020011200\n",
      "IDN 2020011300\n",
      "IDN 2020011400\n",
      "IDN 2020011500\n",
      "IDN 2020011600\n"
     ]
    }
   ],
   "source": [
    "t_start = datetime(2020,1,1)\n",
    "#t_end = datetime.now() - timedelta(days = 1)\n",
    "#t_end = datetime(t_end.year,t_end.month,t_end.day)\n",
    "t_end = datetime(2020,2,1)\n",
    "\n",
    "#for country in ['CIV','COL','IDN','IND','MEX','MMR','MOZ','MYS','NGA','UKR']\n",
    "for country in ['CIV','COL','IDN','IND','MMR','MOZ','MYS','NGA','UKR']:\n",
    "#for country in ['AUS','DEU','GBR']\n",
    "\n",
    "#for country in ['MEX']:\n",
    "    calculate_geostats(country,t_start,t_end,\"admin2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
